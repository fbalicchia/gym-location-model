{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f283672-fc01-4ae7-8d3f-064c8edd2db1",
   "metadata": {},
   "source": [
    "# 2. Transformer Architecture Advantages for POI\n",
    "Captures long-range dependencies between POI visits\n",
    "Understands relationships between non-consecutive visits\n",
    "Can identify periodic patterns (weekly grocery shopping, monthly haircuts)\n",
    "Potential Architecture Approaches:\n",
    "\n",
    "# Conceptual architecture\n",
    "class POITransformer:\n",
    "    - Embedding layers:\n",
    "        * POI ID embedding\n",
    "        * Category embedding (restaurant, gym, store)\n",
    "        * Time embedding (hour, day, season)\n",
    "        * Geographical embedding (lat/long or region)\n",
    "    \n",
    "    - Transformer blocks:\n",
    "        * Multi-head attention for POI relationships\n",
    "        * Position encoding for sequence order\n",
    "        * Temporal attention for time patterns\n",
    "    \n",
    "    - Output heads:\n",
    "        * Next POI classification\n",
    "        * Time-to-next-visit regression\n",
    "        * Category prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c44f0f4-174e-47a2-9541-87e5b7e34aaa",
   "metadata": {},
   "source": [
    "**This advanced implementation demonstrates the key advantages of Transformers for POI prediction:**\n",
    "\n",
    "Key Features:\n",
    "1. Multi-Modal Embeddings\n",
    "POI ID embedding\n",
    "Category embedding (food, work, fitness, etc.)\n",
    "Temporal embeddings (hour, day, season)\n",
    "Geographical embedding (latitude/longitude)\n",
    "Region embedding\n",
    "2. Self-Attention Benefits\n",
    "Long-range dependencies: The model can relate POI visits that are far apart in the sequence\n",
    "Periodic patterns: Identifies weekly gym visits, monthly haircuts\n",
    "Complex relationships: Understands that coffee shop → office, restaurant → cinema\n",
    "3. Multiple Output Heads\n",
    "Next POI prediction\n",
    "Category prediction\n",
    "Time-to-next-visit regression\n",
    "4. Advanced Features\n",
    "Temporal positional encoding for cyclical patterns\n",
    "Causal masking for autoregressive prediction\n",
    "Attention weight analysis for interpretability\n",
    "Rich synthetic data with realistic patterns\n",
    "5. Demonstrated Advantages\n",
    "The attention analysis shows which past POIs influence future predictions\n",
    "Periodic pattern detection (e.g., weekly shopping, bi-weekly gym)\n",
    "Context-aware predictions based on time of day and day of week\n",
    "The model is optimized for Mac M1 with a small dataset (200 sequences) and demonstrates how Transformers excel at capturing complex spatiotemporal patterns in POI trajectories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8920a24-163e-4278-a864-73065cb696f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T15:22:05.117503Z",
     "iopub.status.busy": "2025-09-15T15:22:05.116349Z",
     "iopub.status.idle": "2025-09-15T15:22:06.710880Z",
     "shell.execute_reply": "2025-09-15T15:22:06.710065Z",
     "shell.execute_reply.started": "2025-09-15T15:22:05.117471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "poi_transformer_advanced.py\n",
    "Advanced Transformer Architecture for POI Prediction\n",
    "Fixed version with proper references\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device for Mac M1\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# ==================== Data Structures ====================\n",
    "\n",
    "@dataclass\n",
    "class POI:\n",
    "    \"\"\"Point of Interest data structure\"\"\"\n",
    "    poi_id: int\n",
    "    name: str\n",
    "    category: int\n",
    "    lat: float\n",
    "    lon: float\n",
    "    region: int\n",
    "\n",
    "@dataclass\n",
    "class Visit:\n",
    "    \"\"\"Visit data structure\"\"\"\n",
    "    poi_id: int\n",
    "    timestamp: int  # hour of day\n",
    "    day_of_week: int\n",
    "    season: int\n",
    "    duration: float  # hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a05eed-d74d-4f69-91d6-a6d79f35d93d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T15:22:09.217955Z",
     "iopub.status.busy": "2025-09-15T15:22:09.217574Z",
     "iopub.status.idle": "2025-09-15T15:22:09.235090Z",
     "shell.execute_reply": "2025-09-15T15:22:09.234358Z",
     "shell.execute_reply.started": "2025-09-15T15:22:09.217930Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==================== Advanced Data Generator ====================\n",
    "\n",
    "class AdvancedPOIDataGenerator:\n",
    "    \"\"\"Generate rich synthetic POI data with patterns\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # POI categories\n",
    "        self.categories = {\n",
    "            'food': 0,\n",
    "            'work': 1,\n",
    "            'fitness': 2,\n",
    "            'shopping': 3,\n",
    "            'entertainment': 4,\n",
    "            'personal': 5,\n",
    "            'transport': 6\n",
    "        }\n",
    "        \n",
    "        # Detailed POI types with categories\n",
    "        self.poi_database = {\n",
    "            0: POI(0, 'home', self.categories['personal'], 40.7128, -74.0060, 0),\n",
    "            1: POI(1, 'office', self.categories['work'], 40.7580, -73.9855, 1),\n",
    "            2: POI(2, 'starbucks', self.categories['food'], 40.7489, -73.9680, 1),\n",
    "            3: POI(3, 'gym', self.categories['fitness'], 40.7614, -73.9776, 1),\n",
    "            4: POI(4, 'italian_restaurant', self.categories['food'], 40.7431, -73.9897, 2),\n",
    "            5: POI(5, 'sushi_bar', self.categories['food'], 40.7516, -73.9755, 1),\n",
    "            6: POI(6, 'walmart', self.categories['shopping'], 40.7424, -74.0055, 2),\n",
    "            7: POI(7, 'cinema', self.categories['entertainment'], 40.7580, -73.9855, 1),\n",
    "            8: POI(8, 'barber', self.categories['personal'], 40.7489, -73.9680, 0),\n",
    "            9: POI(9, 'subway_station', self.categories['transport'], 40.7527, -73.9772, 1),\n",
    "            10: POI(10, 'central_park', self.categories['entertainment'], 40.7829, -73.9654, 3),\n",
    "            11: POI(11, 'pharmacy', self.categories['personal'], 40.7480, -73.9870, 0),\n",
    "            12: POI(12, 'bank', self.categories['personal'], 40.7505, -73.9934, 1),\n",
    "        }\n",
    "        \n",
    "        # Temporal patterns\n",
    "        self.time_patterns = {\n",
    "            'morning': (6, 12),\n",
    "            'afternoon': (12, 17),\n",
    "            'evening': (17, 21),\n",
    "            'night': (21, 6)\n",
    "        }\n",
    "        \n",
    "        # Periodic patterns (e.g., weekly gym, monthly barber)\n",
    "        self.periodic_patterns = {\n",
    "            'gym': {'frequency': 'bi-weekly', 'preferred_times': ['morning', 'evening']},\n",
    "            'barber': {'frequency': 'monthly', 'preferred_times': ['afternoon']},\n",
    "            'walmart': {'frequency': 'weekly', 'preferred_times': ['afternoon', 'evening']},\n",
    "            'cinema': {'frequency': 'weekly', 'preferred_times': ['evening', 'night']},\n",
    "        }\n",
    "        \n",
    "        # Long-range dependencies\n",
    "        self.dependency_patterns = {\n",
    "            'starbucks': ['office'],  # Coffee before work\n",
    "            'gym': ['home', 'office'],  # Gym after work or from home\n",
    "            'italian_restaurant': ['cinema'],  # Dinner and movie\n",
    "            'pharmacy': ['home'],  # Medicine then home\n",
    "        }\n",
    "        \n",
    "        self.num_pois = len(self.poi_database)\n",
    "        self.num_categories = len(self.categories)\n",
    "        self.num_regions = 4\n",
    "        self.num_seasons = 4\n",
    "        \n",
    "    def calculate_distance(self, poi1: POI, poi2: POI) -> float:\n",
    "        \"\"\"Calculate distance between two POIs (simplified)\"\"\"\n",
    "        return math.sqrt((poi1.lat - poi2.lat)**2 + (poi1.lon - poi2.lon)**2)\n",
    "    \n",
    "    def generate_trajectory_with_patterns(self, length: int = 20) -> Dict:\n",
    "        \"\"\"Generate trajectory with realistic patterns\"\"\"\n",
    "        trajectory = []\n",
    "        current_hour = 7\n",
    "        current_day = random.randint(0, 6)\n",
    "        current_season = random.randint(0, 3)\n",
    "        visit_history = defaultdict(list)\n",
    "        \n",
    "        # Start from home\n",
    "        current_poi_id = 0\n",
    "        \n",
    "        for step in range(length):\n",
    "            # Record visit\n",
    "            visit = Visit(\n",
    "                poi_id=current_poi_id,\n",
    "                timestamp=current_hour,\n",
    "                day_of_week=current_day,\n",
    "                season=current_season,\n",
    "                duration=random.uniform(0.5, 3.0)\n",
    "            )\n",
    "            trajectory.append(visit)\n",
    "            visit_history[self.poi_database[current_poi_id].name].append(step)\n",
    "            \n",
    "            # Determine next POI based on patterns\n",
    "            next_poi_id = self._select_next_poi(\n",
    "                current_poi_id, \n",
    "                current_hour, \n",
    "                current_day,\n",
    "                visit_history,\n",
    "                step\n",
    "            )\n",
    "            \n",
    "            # Update time\n",
    "            current_hour = (current_hour + int(visit.duration) + 1) % 24\n",
    "            if current_hour < 7:  # New day\n",
    "                current_day = (current_day + 1) % 7\n",
    "            \n",
    "            current_poi_id = next_poi_id\n",
    "        \n",
    "        return self._extract_features(trajectory)\n",
    "    \n",
    "    def _select_next_poi(self, current_poi_id: int, hour: int, day: int, \n",
    "                        history: Dict, step: int) -> int:\n",
    "        \"\"\"Select next POI based on multiple factors\"\"\"\n",
    "        current_poi = self.poi_database[current_poi_id]\n",
    "        candidates = []\n",
    "        weights = []\n",
    "        \n",
    "        for poi_id, poi in self.poi_database.items():\n",
    "            if poi_id == current_poi_id:\n",
    "                continue\n",
    "                \n",
    "            weight = 1.0\n",
    "            \n",
    "            # Distance factor (prefer closer POIs)\n",
    "            distance = self.calculate_distance(current_poi, poi)\n",
    "            weight *= max(0.1, 1.0 - distance * 10)\n",
    "            \n",
    "            # Time appropriateness\n",
    "            if 6 <= hour < 12 and poi.category == self.categories['food']:\n",
    "                weight *= 2.0\n",
    "            elif 12 <= hour < 14 and poi.category == self.categories['food']:\n",
    "                weight *= 3.0\n",
    "            elif 17 <= hour < 21 and poi.category in [self.categories['entertainment'], \n",
    "                                                       self.categories['food']]:\n",
    "                weight *= 2.5\n",
    "            \n",
    "            # Periodic patterns\n",
    "            if poi.name in self.periodic_patterns:\n",
    "                pattern = self.periodic_patterns[poi.name]\n",
    "                if poi.name not in history or not history[poi.name]:\n",
    "                    weight *= 1.5\n",
    "                elif pattern['frequency'] == 'weekly' and step - history[poi.name][-1] > 7:\n",
    "                    weight *= 3.0\n",
    "                elif pattern['frequency'] == 'monthly' and step - history[poi.name][-1] > 30:\n",
    "                    weight *= 4.0\n",
    "            \n",
    "            # Long-range dependencies\n",
    "            if current_poi.name in self.dependency_patterns.get(poi.name, []):\n",
    "                weight *= 2.0\n",
    "            \n",
    "            candidates.append(poi_id)\n",
    "            weights.append(weight)\n",
    "        \n",
    "        # Normalize weights\n",
    "        total_weight = sum(weights)\n",
    "        weights = [w/total_weight for w in weights]\n",
    "        \n",
    "        return random.choices(candidates, weights=weights)[0]\n",
    "    \n",
    "    def _extract_features(self, trajectory: List[Visit]) -> Dict:\n",
    "        \"\"\"Extract features from trajectory\"\"\"\n",
    "        return {\n",
    "            'poi_ids': [v.poi_id for v in trajectory],\n",
    "            'categories': [self.poi_database[v.poi_id].category for v in trajectory],\n",
    "            'timestamps': [v.timestamp for v in trajectory],\n",
    "            'days': [v.day_of_week for v in trajectory],\n",
    "            'seasons': [v.season for v in trajectory],\n",
    "            'regions': [self.poi_database[v.poi_id].region for v in trajectory],\n",
    "            'lats': [self.poi_database[v.poi_id].lat for v in trajectory],\n",
    "            'lons': [self.poi_database[v.poi_id].lon for v in trajectory],\n",
    "            'durations': [v.duration for v in trajectory]\n",
    "        }\n",
    "    \n",
    "    def generate_dataset(self, num_sequences: int = 300) -> List[Dict]:\n",
    "        \"\"\"Generate dataset\"\"\"\n",
    "        dataset = []\n",
    "        for _ in range(num_sequences):\n",
    "            dataset.append(self.generate_trajectory_with_patterns())\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48b554a-a32e-473f-ae77-953a7e646544",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T15:22:18.013469Z",
     "iopub.status.busy": "2025-09-15T15:22:18.013171Z",
     "iopub.status.idle": "2025-09-15T15:22:18.025832Z",
     "shell.execute_reply": "2025-09-15T15:22:18.024821Z",
     "shell.execute_reply.started": "2025-09-15T15:22:18.013444Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==================== Improved Multi-Modal Embedding ====================\n",
    "\n",
    "class MultiModalEmbedding(nn.Module):\n",
    "    \"\"\"Enhanced multi-modal embedding with proper fusion\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        d_model = config['d_model']\n",
    "        \n",
    "        # ============ Modality-specific embeddings ============\n",
    "        self.poi_embedding = nn.Embedding(config['num_pois'], config['poi_embed_dim'])\n",
    "        self.category_embedding = nn.Embedding(config['num_categories'], config['cat_embed_dim'])\n",
    "        self.time_embedding = nn.Embedding(24, config['time_embed_dim'])\n",
    "        self.day_embedding = nn.Embedding(7, config['day_embed_dim'])\n",
    "        self.season_embedding = nn.Embedding(4, config['season_embed_dim'])\n",
    "        self.region_embedding = nn.Embedding(config['num_regions'], config['region_embed_dim'])\n",
    "        \n",
    "        # Geographical embedding (continuous)\n",
    "        self.geo_projection = nn.Sequential(\n",
    "            nn.Linear(2, config['geo_embed_dim']),\n",
    "            nn.LayerNorm(config['geo_embed_dim']),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # ============ Modality-specific projections to common space ============\n",
    "        # Project each modality to d_model with normalization\n",
    "        self.poi_proj = nn.Sequential(\n",
    "            nn.Linear(config['poi_embed_dim'], d_model),\n",
    "            nn.LayerNorm(d_model)\n",
    "        )\n",
    "        \n",
    "        self.cat_proj = nn.Sequential(\n",
    "            nn.Linear(config['cat_embed_dim'], d_model),\n",
    "            nn.LayerNorm(d_model)\n",
    "        )\n",
    "        \n",
    "        self.temporal_proj = nn.Sequential(\n",
    "            nn.Linear(config['time_embed_dim'] + config['day_embed_dim'] + \n",
    "                     config['season_embed_dim'], d_model),\n",
    "            nn.LayerNorm(d_model)\n",
    "        )\n",
    "        \n",
    "        self.spatial_proj = nn.Sequential(\n",
    "            nn.Linear(config['region_embed_dim'] + config['geo_embed_dim'], d_model),\n",
    "            nn.LayerNorm(d_model)\n",
    "        )\n",
    "        \n",
    "        # ============ Learnable modality weights (gating) ============\n",
    "        self.modality_weights = nn.Parameter(torch.ones(4))  # 4 modality groups\n",
    "        \n",
    "        # ============ Non-linear fusion network ============\n",
    "        self.fusion_network = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model * 2),\n",
    "            nn.LayerNorm(d_model * 2),\n",
    "            nn.GELU(),  # Better than ReLU for transformers\n",
    "            nn.Dropout(config.get('dropout', 0.1)),\n",
    "            nn.Linear(d_model * 2, d_model),\n",
    "            nn.LayerNorm(d_model)\n",
    "        )\n",
    "        \n",
    "        # Optional: Cross-modal attention for richer interactions\n",
    "        self.use_cross_attention = config.get('use_cross_attention', False)\n",
    "        if self.use_cross_attention:\n",
    "            self.cross_modal_attention = CrossModalAttention(d_model, num_heads=4)\n",
    "    \n",
    "    def forward(self, poi_ids, categories, timestamps, days, seasons, regions, coords):\n",
    "        # ============ Get embeddings ============\n",
    "        poi_emb = self.poi_embedding(poi_ids)\n",
    "        cat_emb = self.category_embedding(categories)\n",
    "        time_emb = self.time_embedding(timestamps)\n",
    "        day_emb = self.day_embedding(days)\n",
    "        season_emb = self.season_embedding(seasons)\n",
    "        region_emb = self.region_embedding(regions)\n",
    "        geo_emb = self.geo_projection(coords)\n",
    "        \n",
    "        # ============ Group and project modalities ============\n",
    "        # POI identity\n",
    "        poi_features = self.poi_proj(poi_emb)\n",
    "        \n",
    "        # Categorical features\n",
    "        cat_features = self.cat_proj(cat_emb)\n",
    "        \n",
    "        # Temporal features (combined)\n",
    "        temporal_combined = torch.cat([time_emb, day_emb, season_emb], dim=-1)\n",
    "        temporal_features = self.temporal_proj(temporal_combined)\n",
    "        \n",
    "        # Spatial features (combined)\n",
    "        spatial_combined = torch.cat([region_emb, geo_emb], dim=-1)\n",
    "        spatial_features = self.spatial_proj(spatial_combined)\n",
    "        \n",
    "        # ============ Apply learnable modality weights ============\n",
    "        weights = torch.softmax(self.modality_weights, dim=0)\n",
    "        \n",
    "        # Weighted combination of modalities\n",
    "        fused = (weights[0] * poi_features + \n",
    "                weights[1] * cat_features + \n",
    "                weights[2] * temporal_features + \n",
    "                weights[3] * spatial_features)\n",
    "        \n",
    "        # ============ Non-linear fusion ============\n",
    "        fused = self.fusion_network(fused)\n",
    "        \n",
    "        # ============ Optional: Cross-modal attention ============\n",
    "        if self.use_cross_attention:\n",
    "            modalities = torch.stack([\n",
    "                poi_features, cat_features, \n",
    "                temporal_features, spatial_features\n",
    "            ], dim=1)  # (batch, 4, seq_len, d_model)\n",
    "            fused = self.cross_modal_attention(fused, modalities)\n",
    "        \n",
    "        return fused\n",
    "\n",
    "class CrossModalAttention(nn.Module):\n",
    "    \"\"\"Cross-modal attention for richer interactions\"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            d_model, num_heads, batch_first=True\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, query, modalities):\n",
    "        \"\"\"\n",
    "        query: (batch, seq_len, d_model) - fused features\n",
    "        modalities: (batch, num_modalities, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        batch_size, num_mod, seq_len, d_model = modalities.shape\n",
    "        \n",
    "        # Reshape for attention\n",
    "        modalities_flat = modalities.view(batch_size, -1, d_model)\n",
    "        \n",
    "        # Cross-attention\n",
    "        attended, _ = self.attention(query, modalities_flat, modalities_flat)\n",
    "        \n",
    "        # Residual connection\n",
    "        return self.norm(query + attended)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c50beabf-4b7a-44af-93f2-8d1031a67681",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T15:22:25.166195Z",
     "iopub.status.busy": "2025-09-15T15:22:25.165887Z",
     "iopub.status.idle": "2025-09-15T15:22:25.173414Z",
     "shell.execute_reply": "2025-09-15T15:22:25.172584Z",
     "shell.execute_reply.started": "2025-09-15T15:22:25.166171Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==================== Temporal Positional Encoding ====================\n",
    "\n",
    "class TemporalPositionalEncoding(nn.Module):\n",
    "    \"\"\"Temporal-aware positional encoding\"\"\"\n",
    "    \n",
    "    def __init__(self, d_model: int, max_len: int = 500):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Standard positional encoding\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * \n",
    "                           (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "        # Temporal encoding for cyclical patterns\n",
    "        self.hour_encoding = nn.Parameter(torch.randn(24, d_model // 4))\n",
    "        self.day_encoding = nn.Parameter(torch.randn(7, d_model // 4))\n",
    "        \n",
    "    def forward(self, x, timestamps=None, days=None):\n",
    "        # Add standard positional encoding\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        \n",
    "        # Add temporal encodings if provided\n",
    "        if timestamps is not None and days is not None:\n",
    "            batch_size, seq_len = timestamps.shape\n",
    "            \n",
    "            # Get temporal encodings\n",
    "            hour_enc = self.hour_encoding[timestamps]  # (batch, seq, d_model//4)\n",
    "            day_enc = self.day_encoding[days]  # (batch, seq, d_model//4)\n",
    "            \n",
    "            # Pad to match d_model\n",
    "            zeros = torch.zeros(batch_size, seq_len, x.size(-1) // 2).to(x.device)\n",
    "            temporal_enc = torch.cat([hour_enc, day_enc, zeros], dim=-1)\n",
    "            \n",
    "            x = x + temporal_enc\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32f85742-3e38-4dcd-95de-7ca389355c3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T15:22:30.090297Z",
     "iopub.status.busy": "2025-09-15T15:22:30.090008Z",
     "iopub.status.idle": "2025-09-15T15:22:30.095924Z",
     "shell.execute_reply": "2025-09-15T15:22:30.094972Z",
     "shell.execute_reply.started": "2025-09-15T15:22:30.090274Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==================== Transformer Block ====================\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"Custom Transformer block with multi-head attention\"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, nhead, dim_feedforward, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Multi-head attention\n",
    "        self.self_attn = nn.MultiheadAttention(\n",
    "            d_model, nhead, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Feed forward\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_feedforward),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim_feedforward, d_model)\n",
    "        )\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask=None, return_attention=False):\n",
    "        # Self-attention with residual connection\n",
    "        attn_output, attn_weights = self.self_attn(\n",
    "            x, x, x, attn_mask=mask, need_weights=return_attention\n",
    "        )\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        \n",
    "        # Feed forward with residual connection\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        \n",
    "        if return_attention:\n",
    "            return x, attn_weights\n",
    "        return x, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "934b5db5-f5d0-41ad-9ac1-44c991e977a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T15:22:35.328660Z",
     "iopub.status.busy": "2025-09-15T15:22:35.328365Z",
     "iopub.status.idle": "2025-09-15T15:22:35.337202Z",
     "shell.execute_reply": "2025-09-15T15:22:35.336448Z",
     "shell.execute_reply.started": "2025-09-15T15:22:35.328639Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==================== POI Transformer Model ====================\n",
    "\n",
    "class POITransformer(nn.Module):\n",
    "    \"\"\"Advanced Transformer for POI prediction with multiple heads\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # Multi-modal embedding (using the improved version)\n",
    "        self.embedding = MultiModalEmbedding(config)\n",
    "        \n",
    "        # Temporal positional encoding\n",
    "        self.pos_encoding = TemporalPositionalEncoding(config['d_model'])\n",
    "        \n",
    "        # Transformer blocks\n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TransformerBlock(\n",
    "                d_model=config['d_model'],\n",
    "                nhead=config['nhead'],\n",
    "                dim_feedforward=config['dim_feedforward'],\n",
    "                dropout=config['dropout']\n",
    "            ) for _ in range(config['num_layers'])\n",
    "        ])\n",
    "        \n",
    "        # Output heads\n",
    "        self.poi_prediction_head = nn.Linear(config['d_model'], config['num_pois'])\n",
    "        self.category_prediction_head = nn.Linear(config['d_model'], config['num_categories'])\n",
    "        self.time_regression_head = nn.Sequential(\n",
    "            nn.Linear(config['d_model'], config['d_model'] // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(config['d_model'] // 2, 1),\n",
    "            nn.Softplus()  # Ensure positive output\n",
    "        )\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(config['dropout'])\n",
    "        \n",
    "    def forward(self, batch_data, return_attention=False):\n",
    "        # Unpack batch data\n",
    "        poi_ids = batch_data['poi_ids']\n",
    "        categories = batch_data['categories']\n",
    "        timestamps = batch_data['timestamps']\n",
    "        days = batch_data['days']\n",
    "        seasons = batch_data['seasons']\n",
    "        regions = batch_data['regions']\n",
    "        coords = batch_data['coords']\n",
    "        \n",
    "        batch_size, seq_len = poi_ids.shape\n",
    "        \n",
    "        # Get embeddings using the improved multi-modal embedding\n",
    "        x = self.embedding(poi_ids, categories, timestamps, days, seasons, regions, coords)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        x = self.pos_encoding(x, timestamps, days)\n",
    "        \n",
    "        # Apply dropout\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Create causal mask\n",
    "        mask = self.generate_causal_mask(seq_len).to(x.device)\n",
    "        \n",
    "        # Store attention weights if requested\n",
    "        attention_weights = []\n",
    "        \n",
    "        # Apply transformer blocks\n",
    "        for block in self.transformer_blocks:\n",
    "            x, attn = block(x, mask, return_attention=return_attention)\n",
    "            if return_attention:\n",
    "                attention_weights.append(attn)\n",
    "        \n",
    "        # Apply output heads\n",
    "        poi_logits = self.poi_prediction_head(x)\n",
    "        category_logits = self.category_prediction_head(x)\n",
    "        time_to_next = self.time_regression_head(x)\n",
    "        \n",
    "        outputs = {\n",
    "            'poi_logits': poi_logits,\n",
    "            'category_logits': category_logits,\n",
    "            'time_to_next': time_to_next\n",
    "        }\n",
    "        \n",
    "        if return_attention:\n",
    "            outputs['attention_weights'] = attention_weights\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def generate_causal_mask(self, size: int) -> torch.Tensor:\n",
    "        \"\"\"Generate causal mask\"\"\"\n",
    "        mask = torch.triu(torch.ones(size, size), diagonal=1)\n",
    "        return mask.masked_fill(mask == 1, float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80982cde-bf16-487f-8206-217529cbf4f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T15:22:41.329942Z",
     "iopub.status.busy": "2025-09-15T15:22:41.329609Z",
     "iopub.status.idle": "2025-09-15T15:22:41.344453Z",
     "shell.execute_reply": "2025-09-15T15:22:41.343613Z",
     "shell.execute_reply.started": "2025-09-15T15:22:41.329919Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==================== Training and Evaluation ====================\n",
    "\n",
    "class POIDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset for POI trajectories\"\"\"\n",
    "    \n",
    "    def __init__(self, data, seq_length=15):\n",
    "        self.data = data\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        trajectory = self.data[idx]\n",
    "        \n",
    "        # Sample a subsequence\n",
    "        if len(trajectory['poi_ids']) > self.seq_length + 1:\n",
    "            start = random.randint(0, len(trajectory['poi_ids']) - self.seq_length - 1)\n",
    "            end = start + self.seq_length\n",
    "        else:\n",
    "            start = 0\n",
    "            end = len(trajectory['poi_ids']) - 1\n",
    "        \n",
    "        # Extract features\n",
    "        batch_item = {\n",
    "            'poi_ids': torch.tensor(trajectory['poi_ids'][start:end], dtype=torch.long),\n",
    "            'categories': torch.tensor(trajectory['categories'][start:end], dtype=torch.long),\n",
    "            'timestamps': torch.tensor(trajectory['timestamps'][start:end], dtype=torch.long),\n",
    "            'days': torch.tensor(trajectory['days'][start:end], dtype=torch.long),\n",
    "            'seasons': torch.tensor(trajectory['seasons'][start:end], dtype=torch.long),\n",
    "            'regions': torch.tensor(trajectory['regions'][start:end], dtype=torch.long),\n",
    "            'coords': torch.tensor(\n",
    "                [[trajectory['lats'][i], trajectory['lons'][i]] \n",
    "                 for i in range(start, end)], \n",
    "                dtype=torch.float32\n",
    "            ),\n",
    "            'durations': torch.tensor(trajectory['durations'][start:end], dtype=torch.float32)\n",
    "        }\n",
    "        \n",
    "        # Targets (next items)\n",
    "        targets = {\n",
    "            'next_poi': torch.tensor(trajectory['poi_ids'][start+1:end+1], dtype=torch.long),\n",
    "            'next_category': torch.tensor(trajectory['categories'][start+1:end+1], dtype=torch.long),\n",
    "            'next_duration': torch.tensor(trajectory['durations'][start+1:end+1], dtype=torch.float32)\n",
    "        }\n",
    "        \n",
    "        return batch_item, targets\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function for batching\"\"\"\n",
    "    batch_data = defaultdict(list)\n",
    "    batch_targets = defaultdict(list)\n",
    "    \n",
    "    for data, targets in batch:\n",
    "        for key, value in data.items():\n",
    "            batch_data[key].append(value)\n",
    "        for key, value in targets.items():\n",
    "            batch_targets[key].append(value)\n",
    "    \n",
    "    # Stack tensors\n",
    "    for key in batch_data:\n",
    "        batch_data[key] = torch.stack(batch_data[key])\n",
    "    for key in batch_targets:\n",
    "        batch_targets[key] = torch.stack(batch_targets[key])\n",
    "    \n",
    "    return dict(batch_data), dict(batch_targets)\n",
    "\n",
    "def train_model(model, train_loader, config, num_epochs=30):\n",
    "    \"\"\"Train the model with multiple objectives\"\"\"\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "    \n",
    "    # Loss functions\n",
    "    poi_criterion = nn.CrossEntropyLoss()\n",
    "    category_criterion = nn.CrossEntropyLoss()\n",
    "    time_criterion = nn.MSELoss()\n",
    "    \n",
    "    losses_history = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_losses = defaultdict(float)\n",
    "        \n",
    "        for batch_data, targets in train_loader:\n",
    "            # Move to device\n",
    "            for key in batch_data:\n",
    "                batch_data[key] = batch_data[key].to(device)\n",
    "            for key in targets:\n",
    "                targets[key] = targets[key].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(batch_data)\n",
    "            \n",
    "            # Calculate losses\n",
    "            poi_loss = poi_criterion(\n",
    "                outputs['poi_logits'].reshape(-1, config['num_pois']),\n",
    "                targets['next_poi'].reshape(-1)\n",
    "            )\n",
    "            \n",
    "            category_loss = category_criterion(\n",
    "                outputs['category_logits'].reshape(-1, config['num_categories']),\n",
    "                targets['next_category'].reshape(-1)\n",
    "            )\n",
    "            \n",
    "            time_loss = time_criterion(\n",
    "                outputs['time_to_next'].squeeze(-1),\n",
    "                targets['next_duration']\n",
    "            )\n",
    "            \n",
    "            # Combined loss\n",
    "            total_loss = poi_loss + 0.5 * category_loss + 0.3 * time_loss\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Record losses\n",
    "            epoch_losses['poi'] += poi_loss.item()\n",
    "            epoch_losses['category'] += category_loss.item()\n",
    "            epoch_losses['time'] += time_loss.item()\n",
    "            epoch_losses['total'] += total_loss.item()\n",
    "        \n",
    "        # Average losses\n",
    "        for key in epoch_losses:\n",
    "            epoch_losses[key] /= len(train_loader)\n",
    "        \n",
    "        losses_history.append(dict(epoch_losses))\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "            print(f\"  POI Loss: {epoch_losses['poi']:.4f}\")\n",
    "            print(f\"  Category Loss: {epoch_losses['category']:.4f}\")\n",
    "            print(f\"  Time Loss: {epoch_losses['time']:.4f}\")\n",
    "            print(f\"  Total Loss: {epoch_losses['total']:.4f}\")\n",
    "    \n",
    "    return losses_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "984c6303-7373-4959-b180-62aeef20d909",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T15:22:49.669555Z",
     "iopub.status.busy": "2025-09-15T15:22:49.669248Z",
     "iopub.status.idle": "2025-09-15T15:22:49.685756Z",
     "shell.execute_reply": "2025-09-15T15:22:49.684646Z",
     "shell.execute_reply.started": "2025-09-15T15:22:49.669533Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==================== Analysis and Visualization ====================\n",
    "\n",
    "def analyze_attention_patterns(model, sample_data, generator):\n",
    "    \"\"\"Analyze attention patterns to show long-range dependencies\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Prepare sample\n",
    "        for key in sample_data:\n",
    "            if isinstance(sample_data[key], torch.Tensor):\n",
    "                sample_data[key] = sample_data[key].unsqueeze(0).to(device)\n",
    "        \n",
    "        # Get predictions with attention\n",
    "        outputs = model(sample_data, return_attention=True)\n",
    "        \n",
    "        # Get attention weights from last layer\n",
    "        attention = outputs['attention_weights'][-1].cpu().numpy()[0]\n",
    "        \n",
    "        # Analyze patterns\n",
    "        seq_len = attention.shape[-1]\n",
    "        poi_ids = sample_data['poi_ids'].cpu().numpy()[0]\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ATTENTION PATTERN ANALYSIS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Find long-range dependencies\n",
    "        print(\"\\nLong-range Dependencies Detected:\")\n",
    "        for i in range(seq_len):\n",
    "            for j in range(max(0, i-5), i):\n",
    "                if attention[i, j] > 0.15:  # Significant attention\n",
    "                    poi_i = generator.poi_database[poi_ids[i]].name\n",
    "                    poi_j = generator.poi_database[poi_ids[j]].name\n",
    "                    distance = i - j\n",
    "                    print(f\"  {poi_i} (pos {i}) → {poi_j} (pos {j}) \"\n",
    "                          f\"[distance: {distance}, weight: {attention[i, j]:.3f}]\")\n",
    "        \n",
    "        # Find periodic patterns\n",
    "        print(\"\\nPeriodic Patterns (similar POIs attended):\")\n",
    "        poi_positions = defaultdict(list)\n",
    "        for i, poi_id in enumerate(poi_ids):\n",
    "            poi_positions[poi_id].append(i)\n",
    "        \n",
    "        for poi_id, positions in poi_positions.items():\n",
    "            if len(positions) > 1:\n",
    "                poi_name = generator.poi_database[poi_id].name\n",
    "                print(f\"  {poi_name} appears at positions: {positions}\")\n",
    "                \n",
    "                # Check if later occurrences attend to earlier ones\n",
    "                for i in range(1, len(positions)):\n",
    "                    if positions[i] < seq_len and positions[i-1] < seq_len:\n",
    "                        attn_weight = attention[positions[i], positions[i-1]]\n",
    "                        if attn_weight > 0.1:\n",
    "                            print(f\"    → Self-attention weight: {attn_weight:.3f}\")\n",
    "\n",
    "def demonstrate_predictions(model, generator, config):\n",
    "    \"\"\"Demonstrate model predictions with different scenarios\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PREDICTION DEMONSTRATIONS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Scenario 1: Morning routine\n",
    "    print(\"\\n1. Morning Routine Prediction:\")\n",
    "    morning_trajectory = {\n",
    "        'poi_ids': torch.tensor([[0, 2, 1]], dtype=torch.long),  # home → starbucks → office\n",
    "        'categories': torch.tensor([[5, 0, 1]], dtype=torch.long),\n",
    "        'timestamps': torch.tensor([[7, 8, 9]], dtype=torch.long),\n",
    "        'days': torch.tensor([[1, 1, 1]], dtype=torch.long),  # Monday\n",
    "        'seasons': torch.tensor([[0, 0, 0]], dtype=torch.long),\n",
    "        'regions': torch.tensor([[0, 1, 1]], dtype=torch.long),\n",
    "        'coords': torch.tensor([[[40.7128, -74.0060], \n",
    "                                 [40.7489, -73.9680],\n",
    "                                 [40.7580, -73.9855]]], dtype=torch.float32)\n",
    "    }\n",
    "    \n",
    "    for key in morning_trajectory:\n",
    "        morning_trajectory[key] = morning_trajectory[key].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(morning_trajectory)\n",
    "        \n",
    "        # Next POI prediction\n",
    "        poi_probs = F.softmax(outputs['poi_logits'][0, -1], dim=-1)\n",
    "        top_pois = torch.topk(poi_probs, k=3)\n",
    "        \n",
    "        print(\"  Current sequence: Home → Starbucks → Office (Morning)\")\n",
    "        print(\"  Next POI predictions:\")\n",
    "        for prob, idx in zip(top_pois.values, top_pois.indices):\n",
    "            poi_name = generator.poi_database[idx.item()].name\n",
    "            print(f\"    - {poi_name}: {prob.item():.3f}\")\n",
    "        \n",
    "        # Category prediction\n",
    "        cat_probs = F.softmax(outputs['category_logits'][0, -1], dim=-1)\n",
    "        top_cats = torch.topk(cat_probs, k=3)\n",
    "        print(\"  Next category predictions:\")\n",
    "        for prob, idx in zip(top_cats.values, top_cats.indices):\n",
    "            cat_name = list(generator.categories.keys())[idx.item()]\n",
    "            print(f\"    - {cat_name}: {prob.item():.3f}\")\n",
    "        \n",
    "        # Time prediction\n",
    "        predicted_time = outputs['time_to_next'][0, -1].item()\n",
    "        print(f\"  Predicted time to next visit: {predicted_time:.2f} hours\")\n",
    "    \n",
    "    # Scenario 2: Weekend pattern\n",
    "    print(\"\\n2. Weekend Entertainment Prediction:\")\n",
    "    weekend_trajectory = {\n",
    "        'poi_ids': torch.tensor([[0, 10, 4]], dtype=torch.long),  # home → park → restaurant\n",
    "        'categories': torch.tensor([[5, 4, 0]], dtype=torch.long),\n",
    "        'timestamps': torch.tensor([[10, 14, 18]], dtype=torch.long),\n",
    "        'days': torch.tensor([[6, 6, 6]], dtype=torch.long),  # Saturday\n",
    "        'seasons': torch.tensor([[1, 1, 1]], dtype=torch.long),  # Summer\n",
    "        'regions': torch.tensor([[0, 3, 2]], dtype=torch.long),\n",
    "        'coords': torch.tensor([[[40.7128, -74.0060],\n",
    "                                 [40.7829, -73.9654],\n",
    "                                 [40.7431, -73.9897]]], dtype=torch.float32)\n",
    "    }\n",
    "    \n",
    "    for key in weekend_trajectory:\n",
    "        weekend_trajectory[key] = weekend_trajectory[key].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(weekend_trajectory)\n",
    "        poi_probs = F.softmax(outputs['poi_logits'][0, -1], dim=-1)\n",
    "        top_pois = torch.topk(poi_probs, k=3)\n",
    "        \n",
    "        print(\"  Current sequence: Home → Central Park → Italian Restaurant (Weekend)\")\n",
    "        print(\"  Next POI predictions:\")\n",
    "        for prob, idx in zip(top_pois.values, top_pois.indices):\n",
    "            poi_name = generator.poi_database[idx.item()].name\n",
    "            print(f\"    - {poi_name}: {prob.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6e8191d-ea5d-4bd0-bed6-a127fa03ee07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T15:34:53.232386Z",
     "iopub.status.busy": "2025-09-15T15:34:53.232044Z",
     "iopub.status.idle": "2025-09-15T15:34:53.241669Z",
     "shell.execute_reply": "2025-09-15T15:34:53.240187Z",
     "shell.execute_reply.started": "2025-09-15T15:34:53.232360Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==================== Main Execution ====================\n",
    "\n",
    "def main():\n",
    "    print(\"=\"*60)\n",
    "    print(\"ADVANCED POI TRANSFORMER\")\n",
    "    print(\"Demonstrating Self-Attention Benefits\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Configuration\n",
    "    config = {\n",
    "        'num_pois': 13,\n",
    "        'num_categories': 7,\n",
    "        'num_regions': 4,\n",
    "        'poi_embed_dim': 32,\n",
    "        'cat_embed_dim': 16,\n",
    "        'time_embed_dim': 16,\n",
    "        'day_embed_dim': 8,\n",
    "        'season_embed_dim': 8,\n",
    "        'region_embed_dim': 8,\n",
    "        'geo_embed_dim': 16,\n",
    "        'd_model': 128,\n",
    "        'nhead': 8,\n",
    "        'num_layers': 3,\n",
    "        'dim_feedforward': 256,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.001,\n",
    "        'use_cross_attention': True \n",
    "    }\n",
    "    \n",
    "    # Generate data\n",
    "    print(\"\\n1. Generating synthetic POI data with complex patterns...\")\n",
    "    generator = AdvancedPOIDataGenerator()\n",
    "    data = generator.generate_dataset(num_sequences=200)  # Small dataset for M1\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = POIDataset(data, seq_length=10)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, \n",
    "        batch_size=16, \n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    # Create model\n",
    "    print(\"\\n2. Creating Advanced POI Transformer...\")\n",
    "    model = POITransformer(config).to(device)\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"   Total parameters: {num_params:,}\")\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\n3. Training model with multiple objectives...\")\n",
    "    losses = train_model(model, train_loader, config, num_epochs=30)\n",
    "    \n",
    "    if config.get(\"use_cross_attention\", False):\n",
    "        print(\"\\n4. Analyzing cross-attention patterns...\")    \n",
    "    else:\n",
    "        print(\"\\n4. Analyzing self-attention patterns...\")\n",
    "    sample_data, _ = dataset[0]\n",
    "    analyze_attention_patterns(model, sample_data, generator)\n",
    "    \n",
    "    # Demonstrate predictions\n",
    "    print(\"\\n5. Demonstrating predictions...\")\n",
    "    demonstrate_predictions(model, generator, config)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"KEY TRANSFORMER ADVANTAGES DEMONSTRATED:\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"✓ Long-range dependencies: Model can relate distant POI visits\")\n",
    "    print(\"✓ Periodic patterns: Identifies weekly/monthly visit patterns\")\n",
    "    print(\"✓ Multi-modal fusion: Combines POI, category, time, and location\")\n",
    "    print(\"✓ Multiple predictions: POI, category, and time-to-next visit\")\n",
    "    print(\"✓ Attention analysis: Interpretable attention patterns\")\n",
    "    \n",
    "    return model, generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c82cf476-80f1-4b8f-9825-6df6fdeeed56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T15:34:55.757543Z",
     "iopub.status.busy": "2025-09-15T15:34:55.757234Z",
     "iopub.status.idle": "2025-09-15T15:35:09.729371Z",
     "shell.execute_reply": "2025-09-15T15:35:09.728415Z",
     "shell.execute_reply.started": "2025-09-15T15:34:55.757519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ADVANCED POI TRANSFORMER\n",
      "Demonstrating Self-Attention Benefits\n",
      "============================================================\n",
      "\n",
      "1. Generating synthetic POI data with complex patterns...\n",
      "\n",
      "2. Creating Advanced POI Transformer...\n",
      "   Total parameters: 558,289\n",
      "\n",
      "3. Training model with multiple objectives...\n",
      "Epoch 10/30\n",
      "  POI Loss: 1.8773\n",
      "  Category Loss: 1.3618\n",
      "  Time Loss: 0.5222\n",
      "  Total Loss: 2.7149\n",
      "Epoch 20/30\n",
      "  POI Loss: 1.4354\n",
      "  Category Loss: 1.0830\n",
      "  Time Loss: 0.4954\n",
      "  Total Loss: 2.1255\n",
      "Epoch 30/30\n",
      "  POI Loss: 1.2001\n",
      "  Category Loss: 0.8899\n",
      "  Time Loss: 0.4934\n",
      "  Total Loss: 1.7930\n",
      "\n",
      "4. Analyzing cross-attention patterns...\n",
      "\n",
      "============================================================\n",
      "ATTENTION PATTERN ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Long-range Dependencies Detected:\n",
      "  sushi_bar (pos 1) → starbucks (pos 0) [distance: 1, weight: 0.567]\n",
      "  italian_restaurant (pos 2) → starbucks (pos 0) [distance: 2, weight: 0.451]\n",
      "  italian_restaurant (pos 2) → sushi_bar (pos 1) [distance: 1, weight: 0.275]\n",
      "  gym (pos 3) → starbucks (pos 0) [distance: 3, weight: 0.310]\n",
      "  gym (pos 3) → sushi_bar (pos 1) [distance: 2, weight: 0.230]\n",
      "  gym (pos 3) → italian_restaurant (pos 2) [distance: 1, weight: 0.233]\n",
      "  bank (pos 4) → sushi_bar (pos 1) [distance: 3, weight: 0.336]\n",
      "  bank (pos 4) → italian_restaurant (pos 2) [distance: 2, weight: 0.265]\n",
      "  bank (pos 4) → gym (pos 3) [distance: 1, weight: 0.223]\n",
      "  barber (pos 5) → starbucks (pos 0) [distance: 5, weight: 0.158]\n",
      "  barber (pos 5) → bank (pos 4) [distance: 1, weight: 0.442]\n",
      "  sushi_bar (pos 6) → bank (pos 4) [distance: 2, weight: 0.436]\n",
      "  starbucks (pos 7) → bank (pos 4) [distance: 3, weight: 0.374]\n",
      "  walmart (pos 8) → bank (pos 4) [distance: 4, weight: 0.226]\n",
      "  cinema (pos 9) → bank (pos 4) [distance: 5, weight: 0.230]\n",
      "\n",
      "Periodic Patterns (similar POIs attended):\n",
      "  starbucks appears at positions: [0, 7]\n",
      "  sushi_bar appears at positions: [1, 6]\n",
      "\n",
      "5. Demonstrating predictions...\n",
      "\n",
      "============================================================\n",
      "PREDICTION DEMONSTRATIONS\n",
      "============================================================\n",
      "\n",
      "1. Morning Routine Prediction:\n",
      "  Current sequence: Home → Starbucks → Office (Morning)\n",
      "  Next POI predictions:\n",
      "    - home: 0.365\n",
      "    - pharmacy: 0.283\n",
      "    - starbucks: 0.240\n",
      "  Next category predictions:\n",
      "    - personal: 0.611\n",
      "    - food: 0.294\n",
      "    - shopping: 0.059\n",
      "  Predicted time to next visit: 1.56 hours\n",
      "\n",
      "2. Weekend Entertainment Prediction:\n",
      "  Current sequence: Home → Central Park → Italian Restaurant (Weekend)\n",
      "  Next POI predictions:\n",
      "    - pharmacy: 0.440\n",
      "    - central_park: 0.228\n",
      "    - home: 0.076\n",
      "\n",
      "============================================================\n",
      "KEY TRANSFORMER ADVANTAGES DEMONSTRATED:\n",
      "============================================================\n",
      "✓ Long-range dependencies: Model can relate distant POI visits\n",
      "✓ Periodic patterns: Identifies weekly/monthly visit patterns\n",
      "✓ Multi-modal fusion: Combines POI, category, time, and location\n",
      "✓ Multiple predictions: POI, category, and time-to-next visit\n",
      "✓ Attention analysis: Interpretable attention patterns\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, generator = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fd7762-1b04-415f-88f1-623f910e3fac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
