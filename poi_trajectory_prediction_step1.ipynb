{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8e91ea6-e51c-4bb0-8ea4-ca13a0aecf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Tuple, Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device for Mac M1\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# ==================== Data Generation ====================\n",
    "\n",
    "class POIDataGenerator:\n",
    "    \"\"\"Generate synthetic POI trajectory data\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # POI categories with temporal patterns\n",
    "        self.poi_types = {\n",
    "            'home': 0,\n",
    "            'office': 1,\n",
    "            'restaurant': 2,\n",
    "            'gym': 3,\n",
    "            'coffee_shop': 4,\n",
    "            'bar': 5,\n",
    "            'grocery_store': 6,\n",
    "            'park': 7,\n",
    "            'shopping_mall': 8,\n",
    "            'cinema': 9\n",
    "        }\n",
    "        \n",
    "        # Time periods (simplified to 4 periods)\n",
    "        self.time_periods = {\n",
    "            'morning': 0,      # 6-12\n",
    "            'afternoon': 1,    # 12-18\n",
    "            'evening': 2,      # 18-22\n",
    "            'night': 3        # 22-6\n",
    "        }\n",
    "        \n",
    "        # Temporal patterns (what POIs are likely at what times)\n",
    "        self.temporal_patterns = {\n",
    "            'morning': ['home', 'coffee_shop', 'office', 'gym'],\n",
    "            'afternoon': ['office', 'restaurant', 'coffee_shop', 'shopping_mall'],\n",
    "            'evening': ['restaurant', 'bar', 'cinema', 'gym', 'grocery_store'],\n",
    "            'night': ['bar', 'home', 'cinema']\n",
    "        }\n",
    "        \n",
    "        # Transition patterns (likely next POIs)\n",
    "        self.transition_patterns = {\n",
    "            'home': ['coffee_shop', 'office', 'gym', 'grocery_store'],\n",
    "            'office': ['restaurant', 'coffee_shop', 'home', 'gym'],\n",
    "            'restaurant': ['office', 'bar', 'home', 'cinema'],\n",
    "            'gym': ['home', 'office', 'restaurant', 'coffee_shop'],\n",
    "            'coffee_shop': ['office', 'home', 'shopping_mall'],\n",
    "            'bar': ['home', 'restaurant'],\n",
    "            'grocery_store': ['home'],\n",
    "            'park': ['home', 'coffee_shop', 'restaurant'],\n",
    "            'shopping_mall': ['restaurant', 'home', 'cinema'],\n",
    "            'cinema': ['restaurant', 'bar', 'home']\n",
    "        }\n",
    "        \n",
    "        self.num_pois = len(self.poi_types)\n",
    "        self.num_time_periods = len(self.time_periods)\n",
    "        \n",
    "    def get_time_period(self, hour: int) -> int:\n",
    "        \"\"\"Convert hour to time period\"\"\"\n",
    "        if 6 <= hour < 12:\n",
    "            return self.time_periods['morning']\n",
    "        elif 12 <= hour < 18:\n",
    "            return self.time_periods['afternoon']\n",
    "        elif 18 <= hour < 22:\n",
    "            return self.time_periods['evening']\n",
    "        else:\n",
    "            return self.time_periods['night']\n",
    "    \n",
    "    def generate_trajectory(self, seq_length: int = 10) -> Tuple[List[int], List[int]]:\n",
    "        \"\"\"Generate a single trajectory with temporal context\"\"\"\n",
    "        trajectory = []\n",
    "        time_contexts = []\n",
    "        \n",
    "        # Start from home in the morning\n",
    "        current_poi = 'home'\n",
    "        current_hour = 7\n",
    "        \n",
    "        for _ in range(seq_length):\n",
    "            # Get time period\n",
    "            time_period = self.get_time_period(current_hour)\n",
    "            time_contexts.append(time_period)\n",
    "            \n",
    "            # Add current POI to trajectory\n",
    "            trajectory.append(self.poi_types[current_poi])\n",
    "            \n",
    "            # Get possible next POIs based on transitions and time\n",
    "            time_period_name = list(self.time_periods.keys())[time_period]\n",
    "            possible_pois = list(set(self.transition_patterns[current_poi]) & \n",
    "                                set(self.temporal_patterns[time_period_name]))\n",
    "            \n",
    "            # If no intersection, use transition patterns\n",
    "            if not possible_pois:\n",
    "                possible_pois = self.transition_patterns[current_poi]\n",
    "            \n",
    "            # Choose next POI\n",
    "            current_poi = random.choice(possible_pois)\n",
    "            \n",
    "            # Update time (add 1-3 hours)\n",
    "            current_hour = (current_hour + random.randint(1, 3)) % 24\n",
    "        \n",
    "        return trajectory, time_contexts\n",
    "    \n",
    "    def generate_dataset(self, num_sequences: int = 500) -> Dict:\n",
    "        \"\"\"Generate dataset of trajectories\"\"\"\n",
    "        sequences = []\n",
    "        time_contexts = []\n",
    "        \n",
    "        for _ in range(num_sequences):\n",
    "            seq, time_ctx = self.generate_trajectory()\n",
    "            sequences.append(seq)\n",
    "            time_contexts.append(time_ctx)\n",
    "        \n",
    "        return {\n",
    "            'sequences': sequences,\n",
    "            'time_contexts': time_contexts\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f691837a-ee10-4f6f-94c3-6b682afccf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Model Architecture ====================\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Add positional encoding to embeddings\"\"\"\n",
    "    \n",
    "    def __init__(self, d_model: int, max_len: int = 100):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * \n",
    "                           (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "class TrajectoryTransformer(nn.Module):\n",
    "    \"\"\"Transformer Decoder model for POI trajectory prediction\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 num_pois: int,\n",
    "                 num_time_periods: int,\n",
    "                 d_model: int = 64,\n",
    "                 nhead: int = 4,\n",
    "                 num_layers: int = 2,\n",
    "                 dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embeddings\n",
    "        self.poi_embedding = nn.Embedding(num_pois, d_model)\n",
    "        self.time_embedding = nn.Embedding(num_time_periods, d_model // 2)\n",
    "        \n",
    "        # Projection layer to combine POI and time embeddings\n",
    "        self.input_projection = nn.Linear(d_model + d_model // 2, d_model)\n",
    "        \n",
    "        # Positional encoding\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        \n",
    "        # Transformer Decoder\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=d_model * 4,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Output layers\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.output_layer = nn.Linear(d_model, num_pois)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize weights\"\"\"\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "    \n",
    "    def generate_square_subsequent_mask(self, sz: int) -> torch.Tensor:\n",
    "        \"\"\"Generate causal mask for decoder\"\"\"\n",
    "        mask = torch.triu(torch.ones(sz, sz), diagonal=1)\n",
    "        mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "        return mask\n",
    "    \n",
    "    def forward(self, poi_seq, time_seq):\n",
    "        batch_size, seq_len = poi_seq.shape\n",
    "        \n",
    "        # Create causal mask\n",
    "        tgt_mask = self.generate_square_subsequent_mask(seq_len).to(poi_seq.device)\n",
    "        \n",
    "        # Embed POIs and time\n",
    "        poi_emb = self.poi_embedding(poi_seq)  # (batch, seq_len, d_model)\n",
    "        time_emb = self.time_embedding(time_seq)  # (batch, seq_len, d_model//2)\n",
    "        \n",
    "        # Concatenate and project\n",
    "        combined = torch.cat([poi_emb, time_emb], dim=-1)  # (batch, seq_len, d_model + d_model//2)\n",
    "        x = self.input_projection(combined)  # (batch, seq_len, d_model)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        x = self.pos_encoder(x)\n",
    "        \n",
    "        # Apply transformer decoder (using self-attention only, no encoder-decoder attention)\n",
    "        # In this case, we use the decoder as an autoregressive model\n",
    "        memory = torch.zeros_like(x)  # Dummy memory for decoder\n",
    "        x = self.transformer_decoder(\n",
    "            tgt=x,\n",
    "            memory=memory,\n",
    "            tgt_mask=tgt_mask\n",
    "        )\n",
    "        \n",
    "        # Apply dropout and output layer\n",
    "        x = self.dropout(x)\n",
    "        output = self.output_layer(x)  # (batch, seq_len, num_pois)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fadeb78-1382-4f4f-a005-ebd396631b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Training Utils ====================\n",
    "\n",
    "class TrajectoryDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset for trajectory sequences\"\"\"\n",
    "    \n",
    "    def __init__(self, sequences, time_contexts, seq_length=8):\n",
    "        self.sequences = sequences\n",
    "        self.time_contexts = time_contexts\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        time_ctx = self.time_contexts[idx]\n",
    "        \n",
    "        # Create input and target sequences\n",
    "        if len(seq) > self.seq_length + 1:\n",
    "            start_idx = random.randint(0, len(seq) - self.seq_length - 1)\n",
    "            input_seq = seq[start_idx:start_idx + self.seq_length]\n",
    "            target_seq = seq[start_idx + 1:start_idx + self.seq_length + 1]\n",
    "            input_time = time_ctx[start_idx:start_idx + self.seq_length]\n",
    "        else:\n",
    "            input_seq = seq[:-1]\n",
    "            target_seq = seq[1:]\n",
    "            input_time = time_ctx[:-1]\n",
    "        \n",
    "        return (torch.tensor(input_seq, dtype=torch.long),\n",
    "                torch.tensor(input_time, dtype=torch.long),\n",
    "                torch.tensor(target_seq, dtype=torch.long))\n",
    "\n",
    "def train_model(model, train_loader, num_epochs=50, learning_rate=0.001):\n",
    "    \"\"\"Train the transformer model\"\"\"\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch_idx, (poi_seq, time_seq, targets) in enumerate(train_loader):\n",
    "            poi_seq = poi_seq.to(device)\n",
    "            time_seq = time_seq.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(poi_seq, time_seq)\n",
    "            \n",
    "            # Reshape for loss calculation\n",
    "            loss = criterion(outputs.reshape(-1, outputs.size(-1)), targets.reshape(-1))\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        losses.append(avg_loss)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daaac292-c854-420a-b08c-bf7cb8a96b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Inference ====================\n",
    "\n",
    "def predict_next_poi(model, poi_sequence, time_sequence, poi_names, top_k=3):\n",
    "    \"\"\"Predict the next POI given a sequence\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Convert to tensors\n",
    "        poi_tensor = torch.tensor(poi_sequence, dtype=torch.long).unsqueeze(0).to(device)\n",
    "        time_tensor = torch.tensor(time_sequence, dtype=torch.long).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Get predictions\n",
    "        outputs = model(poi_tensor, time_tensor)\n",
    "        \n",
    "        # Get probabilities for the last position\n",
    "        last_output = outputs[0, -1, :]\n",
    "        probs = torch.softmax(last_output, dim=-1)\n",
    "        \n",
    "        # Get top-k predictions\n",
    "        top_probs, top_indices = torch.topk(probs, k=top_k)\n",
    "        \n",
    "        predictions = []\n",
    "        for prob, idx in zip(top_probs, top_indices):\n",
    "            poi_name = poi_names[idx.item()]\n",
    "            predictions.append((poi_name, prob.item()))\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9391f29f-d11a-49dd-afa6-63f45976f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"POI Trajectory Prediction with Transformer\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Generate synthetic data\n",
    "    print(\"\\n1. Generating synthetic trajectory data...\")\n",
    "    generator = POIDataGenerator()\n",
    "    data = generator.generate_dataset(num_sequences=300)  # Small dataset for Mac M1\n",
    "    \n",
    "    # Prepare data\n",
    "    dataset = TrajectoryDataset(data['sequences'], data['time_contexts'])\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Create model\n",
    "    print(\"\\n2. Creating Transformer model...\")\n",
    "    model = TrajectoryTransformer(\n",
    "        num_pois=generator.num_pois,\n",
    "        num_time_periods=generator.num_time_periods,\n",
    "        d_model=64,\n",
    "        nhead=4,\n",
    "        num_layers=2,\n",
    "        dropout=0.1\n",
    "    ).to(device)\n",
    "    \n",
    "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"   Model parameters: {num_params:,}\")\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\n3. Training model...\")\n",
    "    losses = train_model(model, train_loader, num_epochs=50)\n",
    "    print(f\"   Final training loss: {losses[-1]:.4f}\")\n",
    "    \n",
    "    # Inference examples\n",
    "    print(\"\\n4. Inference Examples:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Reverse mapping for POI names\n",
    "    poi_names = {v: k for k, v in generator.poi_types.items()}\n",
    "    time_names = {v: k for k, v in generator.time_periods.items()}\n",
    "    \n",
    "    # Example 1: Morning routine\n",
    "    print(\"\\nExample 1: Morning Routine\")\n",
    "    poi_sequence = [\n",
    "        generator.poi_types['home'],\n",
    "        generator.poi_types['coffee_shop'],\n",
    "        generator.poi_types['office']\n",
    "    ]\n",
    "    time_sequence = [\n",
    "        generator.time_periods['morning'],\n",
    "        generator.time_periods['morning'],\n",
    "        generator.time_periods['morning']\n",
    "    ]\n",
    "    \n",
    "    print(\"Input sequence: Home → Coffee Shop → Office\")\n",
    "    print(\"Time context: Morning → Morning → Morning\")\n",
    "    predictions = predict_next_poi(model, poi_sequence, time_sequence, poi_names)\n",
    "    print(\"Next POI predictions:\")\n",
    "    for poi, prob in predictions:\n",
    "        print(f\"  - {poi}: {prob:.3f}\")\n",
    "    \n",
    "    # Example 2: Evening activities\n",
    "    print(\"\\nExample 2: Evening Activities\")\n",
    "    poi_sequence = [\n",
    "        generator.poi_types['office'],\n",
    "        generator.poi_types['gym'],\n",
    "        generator.poi_types['restaurant']\n",
    "    ]\n",
    "    time_sequence = [\n",
    "        generator.time_periods['afternoon'],\n",
    "        generator.time_periods['evening'],\n",
    "        generator.time_periods['evening']\n",
    "    ]\n",
    "    \n",
    "    print(\"Input sequence: Office → Gym → Restaurant\")\n",
    "    print(\"Time context: Afternoon → Evening → Evening\")\n",
    "    predictions = predict_next_poi(model, poi_sequence, time_sequence, poi_names)\n",
    "    print(\"Next POI predictions:\")\n",
    "    for poi, prob in predictions:\n",
    "        print(f\"  - {poi}: {prob:.3f}\")\n",
    "    \n",
    "    # Example 3: Weekend shopping\n",
    "    print(\"\\nExample 3: Weekend Shopping\")\n",
    "    poi_sequence = [\n",
    "        generator.poi_types['home'],\n",
    "        generator.poi_types['grocery_store'],\n",
    "        generator.poi_types['shopping_mall']\n",
    "    ]\n",
    "    time_sequence = [\n",
    "        generator.time_periods['morning'],\n",
    "        generator.time_periods['afternoon'],\n",
    "        generator.time_periods['afternoon']\n",
    "    ]\n",
    "    \n",
    "    print(\"Input sequence: Home → Grocery Store → Shopping Mall\")\n",
    "    print(\"Time context: Morning → Afternoon → Afternoon\")\n",
    "    predictions = predict_next_poi(model, poi_sequence, time_sequence, poi_names)\n",
    "    print(\"Next POI predictions:\")\n",
    "    for poi, prob in predictions:\n",
    "        print(f\"  - {poi}: {prob:.3f}\")\n",
    "    \n",
    "    # Interactive prediction\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Model trained successfully!\")\n",
    "    print(\"The model can now predict the next POI based on:\")\n",
    "    print(\"  • Historical trajectory sequence\")\n",
    "    print(\"  • Temporal context (time of day)\")\n",
    "    print(\"  • Learned transition patterns\")\n",
    "    \n",
    "    return model, generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2adb8417-08e3-489e-9a57-5ddef183dce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "POI Trajectory Prediction with Transformer\n",
      "============================================================\n",
      "\n",
      "1. Generating synthetic trajectory data...\n",
      "\n",
      "2. Creating Transformer model...\n",
      "   Model parameters: 141,130\n",
      "\n",
      "3. Training model...\n",
      "Epoch [10/50], Loss: 0.7975\n",
      "Epoch [20/50], Loss: 0.7693\n",
      "Epoch [30/50], Loss: 0.7501\n",
      "Epoch [40/50], Loss: 0.7362\n",
      "Epoch [50/50], Loss: 0.7365\n",
      "   Final training loss: 0.7365\n",
      "\n",
      "4. Inference Examples:\n",
      "------------------------------------------------------------\n",
      "\n",
      "Example 1: Morning Routine\n",
      "Input sequence: Home → Coffee Shop → Office\n",
      "Time context: Morning → Morning → Morning\n",
      "Next POI predictions:\n",
      "  - home: 0.372\n",
      "  - coffee_shop: 0.344\n",
      "  - gym: 0.259\n",
      "\n",
      "Example 2: Evening Activities\n",
      "Input sequence: Office → Gym → Restaurant\n",
      "Time context: Afternoon → Evening → Evening\n",
      "Next POI predictions:\n",
      "  - bar: 0.493\n",
      "  - cinema: 0.479\n",
      "  - home: 0.015\n",
      "\n",
      "Example 3: Weekend Shopping\n",
      "Input sequence: Home → Grocery Store → Shopping Mall\n",
      "Time context: Morning → Afternoon → Afternoon\n",
      "Next POI predictions:\n",
      "  - restaurant: 0.996\n",
      "  - office: 0.002\n",
      "  - coffee_shop: 0.001\n",
      "\n",
      "============================================================\n",
      "Model trained successfully!\n",
      "The model can now predict the next POI based on:\n",
      "  • Historical trajectory sequence\n",
      "  • Temporal context (time of day)\n",
      "  • Learned transition patterns\n"
     ]
    }
   ],
   "source": [
    "model, generator = main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d06e62-8bf3-4f9b-af36-482724176064",
   "metadata": {},
   "source": [
    "1. **Causal Masking**: The decoder uses a triangular mask to ensure the model can only attend to previous positions (autoregressive behavior), which is essential for next-token prediction.\n",
    "\n",
    "2. **Better for Sequential Prediction**: Decoders are designed for generating sequences one token at a time, making them ideal for trajectory prediction where we want to predict the next POI.\n",
    "\n",
    "3. **Self-Attention with Causality**: The model learns dependencies between POIs while respecting the temporal order of visits.\n",
    "\n",
    "4. **More Natural Architecture**: For next-POI prediction, we're essentially doing language modeling but with POIs instead of words, and decoder-only transformers (like GPT) are the standard for this task.\n",
    "\n",
    "The model now properly uses `TransformerDecoder` with causal masking, making it more suitable for trajectory prediction tasks. The training process remains efficient for Mac M1 with minimal data (300 sequences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4355de63-95ed-4e53-a894-33547f523c97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
